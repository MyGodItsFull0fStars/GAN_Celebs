{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from gan_models import Generator, Discriminator\n",
    "\n",
    "from utils import device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manual_seed: int = 42\n",
    "# manual_seed = random.randint(1, 10000)\n",
    "torch.manual_seed(manual_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root: str = 'celeba/'\n",
    "\n",
    "num_workers: int = 2\n",
    "\n",
    "batch_size: int = 128\n",
    "\n",
    "# Spatial size of training images.\n",
    "# All images will be resized to this size using a transformer\n",
    "image_size = 64\n",
    "\n",
    "# number of color channels, for color images this is 3\n",
    "num_channels: int = 3\n",
    "\n",
    "# Size(dim) of z latent vector (i.e. size of generator input)\n",
    "latent_dim_z: int = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "num_gen_features = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "num_dis_features = 64\n",
    "\n",
    "num_epochs: int = 1\n",
    "\n",
    "learning_rate: float = 0.0002\n",
    "\n",
    "# Beta 1 hyperparam for Adam optimizer\n",
    "beta_1: float = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode\n",
    "num_gpu: int = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=data_root,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(\n",
    "                                   (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.title('Training Images')\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[\n",
    "           :64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = Generator(latent_dim_z, num_gen_features, num_channels).to(device)\n",
    "gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_model = Discriminator(num_dis_features, num_channels).to(device)\n",
    "dis_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle multi-gpu if desired\n",
    "# if (device.type == 'cuda') and (num_gpu > 1):\n",
    "#     gen_model = nn.DataParallel(gen_model, list(range(num_gpu)))\n",
    "#     dis_model = nn.DataParallel(gen_model, list(range(num_gpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Loss Function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "# the progression of the generator\n",
    "fixed_noise = torch.randn(64, latent_dim_z, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label: float = 1.\n",
    "fake_label: float = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AdamW optimizers for both G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_dis = optim.AdamW(dis_model.parameters(), lr=learning_rate, betas=(beta_1, 0.999))\n",
    "optimizer_gen = optim.AdamW(gen_model.parameters(), lr=learning_rate, betas=(beta_1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print('Starting Training Loop...')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: ({epoch}/{num_epochs})')\n",
    "\n",
    "    for idx, (input_data, _) in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # Train with all-real batch\n",
    "        dis_model.zero_grad()\n",
    "\n",
    "        input_data = input_data.to(device)\n",
    "        b_size = input_data.size(0)\n",
    "        label = torch.full((b_size,), real_label,\n",
    "                           dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through Discriminator\n",
    "        output = dis_model(input_data).view(-1)\n",
    "        real_dis_loss = criterion(output, label)\n",
    "        real_dis_loss.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # Train with all-fake batch\n",
    "\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, latent_dim_z, 1, 1, device=device)\n",
    "\n",
    "        # Generate fake image batch with Generator\n",
    "        fake = gen_model(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all-fake batch with D\n",
    "        output = dis_model(fake.detach()).view(-1)\n",
    "        # Calculate Discriminators loss on the all-fake batch\n",
    "        fake_dis_loss = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with the previous gradients\n",
    "        fake_dis_loss.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of Discriminator as sum over the fake and the real batches\n",
    "        discriminator_loss = real_dis_loss + fake_dis_loss\n",
    "        # Update Discriminator\n",
    "        optimizer_dis.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        gen_model.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated the Discriminator, perform another forward pass of all-fake batch through D\n",
    "        output = dis_model(fake).view(-1)\n",
    "        # Calculate Generators loss based on this output\n",
    "        generator_loss = criterion(output, label)\n",
    "        # Calculate gradients for Generator\n",
    "        generator_loss.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update Generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if idx % 50 == 0:\n",
    "            print(f'[{epoch}/{num_epochs}][{idx}/{len(dataloader)}]\\tLoss_D: {discriminator_loss.item():.4f}\\tLoss_G: {generator_loss.item():.4f}\\tD(x): {D_x}.4f\\tD(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(generator_loss.item())\n",
    "        D_losses.append(discriminator_loss.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (idx == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = gen_model(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "258adb7323983bd1f8321dc6655f1c2bbeb96a5281da7379235e0539fa23930f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
